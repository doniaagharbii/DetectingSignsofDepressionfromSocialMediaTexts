{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0f5f587a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from string import punctuation\n",
    "from os import listdir\n",
    "from nltk.corpus import stopwords\n",
    "from pickle import dump, load\n",
    "from keras.layers import Input, Dense, Flatten, Dropout, Embedding, Conv1D, MaxPooling1D, concatenate\n",
    "from keras.layers import Attention, Lambda, Bidirectional\n",
    "from keras import backend as K\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils.vis_utils import plot_model\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.models import Model, load_model\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.under_sampling import RandomUnderSampler\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58f6fe53",
   "metadata": {},
   "source": [
    "## Develop GRU Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ad4efd57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load a clean dataset\n",
    "def load_dataset(filename):\n",
    "\treturn load(open(filename, 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2a990cde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit a tokenizer\n",
    "def create_tokenizer(lines):\n",
    "\ttokenizer = Tokenizer()\n",
    "\ttokenizer.fit_on_texts(lines)\n",
    "\treturn tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "309e9928",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the maximum document length\n",
    "def max_length(lines):\n",
    "\treturn max([len(s.split()) for s in lines])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f3029668",
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode a list of lines\n",
    "def encode_text(tokenizer, lines, length):\n",
    "\t# integer encode\n",
    "\tencoded = tokenizer.texts_to_sequences(lines)\n",
    "\t# pad encoded sequences\n",
    "\tpadded = pad_sequences(encoded, maxlen=length, padding='post')\n",
    "\treturn padded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "899b0b8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import GRU\n",
    "\n",
    "def define_model(length, vocab_size):\n",
    "    # Input layer\n",
    "    inputs = Input(shape=(length,))\n",
    "    embedding = Embedding(vocab_size, 100)(inputs)\n",
    "\n",
    "    # GRU layer\n",
    "    gru1 = GRU(100, return_sequences=True)(embedding)\n",
    "    gru2 = GRU(100, return_sequences=True)(gru1)\n",
    "    drop = Dropout(0.5)(gru2)\n",
    "\n",
    "    # Attention layer\n",
    "    atten = Attention()([drop, drop])  \n",
    "\n",
    "    # Attention weights\n",
    "    atten_weights = Lambda(lambda x: K.mean(x, axis=1))(atten)\n",
    "    \n",
    "    # Flatten the GRU output\n",
    "    flat = Flatten()(drop)\n",
    "\n",
    "    # Merge attention weights with main output\n",
    "    merged = concatenate([flat, atten_weights])\n",
    "\n",
    "    # Dense layers\n",
    "    dense1 = Dense(10, activation='relu')(merged)\n",
    "    dense2 = Dense(50, activation='relu')(dense1) \n",
    "    main_output = Dense(3, activation='softmax', name='main_output')(dense2)\n",
    "    \n",
    "    # Create the model\n",
    "    model = Model(inputs=inputs, outputs=[main_output, atten_weights])\n",
    "\n",
    "    # Compile\n",
    "    model.compile(loss={'main_output': 'sparse_categorical_crossentropy'}, optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "    # Summarize\n",
    "    print(model.summary())\n",
    "    plot_model(model, show_shapes=True, to_file='GRUModel.png')\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "051b298f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max document length: 3158\n",
      "Vocabulary size: 11931\n",
      "(13542, 3158)\n"
     ]
    }
   ],
   "source": [
    " # load training dataset\n",
    "trainLines, trainLabels = load_dataset('../Dataset/train.pkl')\n",
    "# create tokenizer\n",
    "tokenizer = create_tokenizer(trainLines)\n",
    "# calculate max document length\n",
    "length = max_length(trainLines)\n",
    "# calculate vocabulary size\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "print('Max document length: %d' % length)\n",
    "print('Vocabulary size: %d' % vocab_size)\n",
    "# encode data\n",
    "trainX = encode_text(tokenizer, trainLines, length)\n",
    "print(trainX.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8e23d0ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 3158)]       0           []                               \n",
      "                                                                                                  \n",
      " embedding (Embedding)          (None, 3158, 100)    1193100     ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " gru (GRU)                      (None, 3158, 100)    60600       ['embedding[0][0]']              \n",
      "                                                                                                  \n",
      " gru_1 (GRU)                    (None, 3158, 100)    60600       ['gru[0][0]']                    \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, 3158, 100)    0           ['gru_1[0][0]']                  \n",
      "                                                                                                  \n",
      " attention (Attention)          (None, 3158, 100)    0           ['dropout[0][0]',                \n",
      "                                                                  'dropout[0][0]']                \n",
      "                                                                                                  \n",
      " flatten (Flatten)              (None, 315800)       0           ['dropout[0][0]']                \n",
      "                                                                                                  \n",
      " lambda (Lambda)                (None, 100)          0           ['attention[0][0]']              \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 315900)       0           ['flatten[0][0]',                \n",
      "                                                                  'lambda[0][0]']                 \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 10)           3159010     ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 50)           550         ['dense[0][0]']                  \n",
      "                                                                                                  \n",
      " main_output (Dense)            (None, 3)            153         ['dense_1[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 4,474,013\n",
      "Trainable params: 4,474,013\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Epoch 1/15\n",
      "424/424 [==============================] - 10169s 24s/step - loss: 0.6015 - main_output_loss: 0.6015 - main_output_accuracy: 0.7310 - lambda_accuracy: 0.0038\n",
      "Epoch 2/15\n",
      "424/424 [==============================] - 10365s 24s/step - loss: 0.2113 - main_output_loss: 0.2113 - main_output_accuracy: 0.9347 - lambda_accuracy: 0.0000e+00\n",
      "Epoch 3/15\n",
      "424/424 [==============================] - 9853s 23s/step - loss: 0.1268 - main_output_loss: 0.1268 - main_output_accuracy: 0.9664 - lambda_accuracy: 0.0000e+00\n",
      "Epoch 4/15\n",
      "424/424 [==============================] - 10783s 25s/step - loss: 0.0925 - main_output_loss: 0.0925 - main_output_accuracy: 0.9754 - lambda_accuracy: 0.0000e+00\n",
      "Epoch 5/15\n",
      "424/424 [==============================] - 11094s 26s/step - loss: 0.0954 - main_output_loss: 0.0954 - main_output_accuracy: 0.9744 - lambda_accuracy: 0.0000e+00\n",
      "Epoch 6/15\n",
      "424/424 [==============================] - 10637s 25s/step - loss: 0.0766 - main_output_loss: 0.0766 - main_output_accuracy: 0.9788 - lambda_accuracy: 0.0000e+00\n",
      "Epoch 7/15\n",
      "424/424 [==============================] - 9763s 23s/step - loss: 0.0505 - main_output_loss: 0.0505 - main_output_accuracy: 0.9861 - lambda_accuracy: 0.0000e+00\n",
      "Epoch 8/15\n",
      "424/424 [==============================] - 9545s 23s/step - loss: 0.0583 - main_output_loss: 0.0583 - main_output_accuracy: 0.9825 - lambda_accuracy: 0.0000e+00\n",
      "Epoch 9/15\n",
      "424/424 [==============================] - 9360s 22s/step - loss: 0.0613 - main_output_loss: 0.0613 - main_output_accuracy: 0.9815 - lambda_accuracy: 0.0000e+00\n",
      "Epoch 10/15\n",
      "424/424 [==============================] - 9100s 21s/step - loss: 0.0434 - main_output_loss: 0.0434 - main_output_accuracy: 0.9861 - lambda_accuracy: 0.0000e+00\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# define model\n",
    "model = define_model(length, vocab_size)\n",
    "\n",
    "# Define early stopping callback\n",
    "early_stopping = EarlyStopping(monitor='main_output_accuracy', patience=3)\n",
    "\n",
    "# Train the model with early stopping\n",
    "model.fit(trainX, np.array(trainLabels), epochs=15, batch_size=32,\n",
    "          callbacks=[early_stopping])\n",
    "\n",
    "# save the model\n",
    "model.save('../Models/gru.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1078e73b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Define the file path\n",
    "file_path = '../Models/gru.h5'\n",
    "\n",
    "# Check if the file exists\n",
    "if os.path.isfile(file_path):\n",
    "    # Delete the file\n",
    "    os.remove(file_path)\n",
    "\n",
    "# Save the model\n",
    "model.save(file_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
